#!/usr/bin/env python3
"""
Memory 2.0 - å¯¹è¯å†å²å‹ç¼©å·¥å…·
ä½¿ç”¨ DeepSeek-OCR-2 å°†æ–‡æœ¬å‹ç¼©ä¸º Vision Tokens
"""

import os
import sys
import json
import subprocess
from pathlib import Path
from datetime import datetime

# é…ç½®
MODEL_PATH = os.path.expanduser("~/.lmstudio/models/mlx-community/DeepSeek-OCR-2-bf16")
PYTHON = "/opt/homebrew/bin/python3.13"
TEMP_DIR = Path("/tmp/memory-compress")
TEMP_DIR.mkdir(exist_ok=True)


def text_to_image(text: str, output_path: Path, width: int = 1200, font_size: int = 14) -> bool:
    """å°†æ–‡æœ¬æ¸²æŸ“ä¸ºé«˜å¯†åº¦ PNG å›¾ç‰‡"""
    try:
        from PIL import Image, ImageDraw, ImageFont
    except ImportError:
        print("âŒ éœ€è¦å®‰è£… Pillow: pip install Pillow")
        return False
    
    # è®¡ç®—è¡Œæ•°å’Œé«˜åº¦
    lines = []
    max_chars_per_line = width // (font_size // 2)  # ä¼°ç®—æ¯è¡Œå­—ç¬¦æ•°
    
    for paragraph in text.split('\n'):
        if not paragraph.strip():
            lines.append('')
            continue
        # è‡ªåŠ¨æ¢è¡Œ
        while len(paragraph) > max_chars_per_line:
            lines.append(paragraph[:max_chars_per_line])
            paragraph = paragraph[max_chars_per_line:]
        lines.append(paragraph)
    
    # è®¡ç®—å›¾ç‰‡é«˜åº¦
    line_height = font_size + 4
    height = max(100, len(lines) * line_height + 40)
    
    # åˆ›å»ºå›¾ç‰‡
    img = Image.new('RGB', (width, height), color='white')
    draw = ImageDraw.Draw(img)
    
    # å°è¯•åŠ è½½å­—ä½“
    try:
        font = ImageFont.truetype("/System/Library/Fonts/PingFang.ttc", font_size)
    except:
        try:
            font = ImageFont.truetype("/System/Library/Fonts/Helvetica.ttc", font_size)
        except:
            font = ImageFont.load_default()
    
    # ç»˜åˆ¶æ–‡æœ¬
    y = 20
    for line in lines:
        draw.text((20, y), line, fill='black', font=font)
        y += line_height
    
    # ä¿å­˜
    img.save(output_path, 'PNG', optimize=True)
    return True


def ocr_image(image_path: Path, prompt: str = "Extract all text from this image.") -> dict:
    """ä½¿ç”¨ DeepSeek-OCR è¯†åˆ«å›¾ç‰‡"""
    cmd = [
        PYTHON, "-m", "mlx_vlm.generate",
        "--model", MODEL_PATH,
        "--image", str(image_path),
        "--max-tokens", "500",
        "--prompt", prompt
    ]
    
    result = subprocess.run(cmd, capture_output=True, text=True, timeout=120)
    output = result.stdout + result.stderr
    
    # è§£æè¾“å‡º
    lines = output.split('\n')
    text_lines = []
    capture = False
    prompt_tokens = 0
    gen_tokens = 0
    
    for line in lines:
        if "Prompt:" in line and "tokens-per-sec" in line:
            parts = line.split()
            prompt_tokens = int(parts[1])
        elif "Generation:" in line and "tokens-per-sec" in line:
            parts = line.split()
            gen_tokens = int(parts[1])
        elif capture and line.strip() and "==========" not in line:
            text_lines.append(line)
        elif prompt in line:
            capture = True
    
    return {
        "text": '\n'.join(text_lines),
        "prompt_tokens": prompt_tokens,
        "generation_tokens": gen_tokens,
        "image_path": str(image_path)
    }


def compress_memory(text: str, mode: str = "base") -> dict:
    """
    å‹ç¼©è®°å¿†æ–‡æœ¬
    
    Modes:
    - tiny: æç®€æ‘˜è¦ (~64 vision tokens)
    - small: ç®€çŸ­æ‘˜è¦ (~100 vision tokens)
    - base: æ ‡å‡†å‹ç¼© (~256 vision tokens)
    - large: è¯¦ç»†ä¿ç•™ (~400 vision tokens)
    """
    
    prompts = {
        "tiny": "Extract only the most critical facts from this text in 2-3 bullet points.",
        "small": "Summarize the key information in 5 bullet points.",
        "base": "Extract and organize all important information from this text.",
        "large": "Preserve all meaningful details from this conversation history."
    }
    
    prompt = prompts.get(mode, prompts["base"])
    
    # ç»Ÿè®¡åŸå§‹ tokens (ç²—ç•¥ä¼°è®¡: 1 token â‰ˆ 4 å­—ç¬¦è‹±æ–‡ / 1.5 å­—ç¬¦ä¸­æ–‡)
    orig_tokens = len(text) // 2  # ç®€å•ä¼°ç®—
    
    # æ¸²æŸ“ä¸ºå›¾ç‰‡
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    image_path = TEMP_DIR / f"memory_{timestamp}.png"
    
    print(f"ğŸ“ åŸå§‹æ–‡æœ¬: {len(text)} å­—ç¬¦, ~{orig_tokens} tokens")
    print(f"ğŸ¨ æ¸²æŸ“å›¾ç‰‡: {image_path}")
    
    if not text_to_image(text, image_path):
        return {"error": "Failed to render image"}
    
    # OCR å‹ç¼©
    print(f"ğŸ” OCR å‹ç¼© (mode: {mode})...")
    result = ocr_image(image_path, prompt)
    
    # è®¡ç®—å‹ç¼©æ¯”
    compressed_tokens = result["generation_tokens"]
    compression_ratio = orig_tokens / max(compressed_tokens, 1)
    
    result["original_chars"] = len(text)
    result["original_tokens_est"] = orig_tokens
    result["compression_ratio"] = round(compression_ratio, 1)
    result["mode"] = mode
    
    print(f"âœ… å‹ç¼©å®Œæˆ!")
    print(f"   åŸå§‹: ~{orig_tokens} tokens")
    print(f"   å‹ç¼©å: {compressed_tokens} tokens")
    print(f"   å‹ç¼©æ¯”: {compression_ratio:.1f}x")
    
    return result


def demo():
    """æ¼”ç¤ºå‹ç¼©æ•ˆæœ"""
    
    # æ¨¡æ‹Ÿå¯¹è¯å†å²
    sample_conversation = """
ç”¨æˆ·: å¸®æˆ‘é…ç½®ä¸€ä¸‹ OpenClaw çš„æ¨¡å‹
åŠ©æ‰‹: å¥½çš„ï¼Œæˆ‘æ¥å¸®ä½ é…ç½®ã€‚é¦–å…ˆéœ€è¦æ·»åŠ  provider...

ç”¨æˆ·: æ·»åŠ  DeepSeek çš„ API
åŠ©æ‰‹: å·²æ·»åŠ  DeepSeek providerï¼ŒåŒ…å« deepseek-chat å’Œ deepseek-reasoner ä¸¤ä¸ªæ¨¡å‹ã€‚

ç”¨æˆ·: å†åŠ ä¸Š NVIDIA çš„æ¨¡å‹
åŠ©æ‰‹: å·²é…ç½® NVIDIA providerï¼ŒåŒ…å« Kimi K2.5ã€Llama 3.3 70Bã€DeepSeek R1 Distill ç­‰æ¨¡å‹ã€‚

ç”¨æˆ·: Google AI Studio ä¹Ÿè¦
åŠ©æ‰‹: å·²æ·»åŠ  Google AI Studioï¼ŒåŒ…å« Gemini 3 Proã€Gemini 2.5 Flash ç­‰ 8 ä¸ªæ¨¡å‹ã€‚

ç”¨æˆ·: ç°åœ¨æœ‰å¤šå°‘æ¨¡å‹äº†ï¼Ÿ
åŠ©æ‰‹: æ€»å…± 42 ä¸ªæ¨¡å‹ï¼Œæ¶µç›– 6 ä¸ª providerï¼š
- Google AI Studio: 8 ä¸ª
- OpenAI/Codex: 7 ä¸ª  
- xAI: 8 ä¸ª
- NVIDIA: 15 ä¸ª
- DeepSeek: 2 ä¸ª
- Antigravity: 2 ä¸ª

ç”¨æˆ·: å¤ªæ£’äº†ï¼
åŠ©æ‰‹: ä½ çš„æ¨¡å‹åº“éå¸¸è±ªåï¼Œå¯ä»¥æ ¹æ®ä¸åŒä»»åŠ¡é€‰æ‹©æœ€åˆé€‚çš„æ¨¡å‹ã€‚
"""
    
    print("=" * 60)
    print("ğŸ§  Memory 2.0 å‹ç¼©æ¼”ç¤º")
    print("=" * 60)
    
    result = compress_memory(sample_conversation, mode="base")
    
    print("\nğŸ“‹ å‹ç¼©åçš„è®°å¿†:")
    print("-" * 40)
    print(result.get("text", ""))
    print("-" * 40)
    
    return result


if __name__ == "__main__":
    if len(sys.argv) > 1:
        # ä»æ–‡ä»¶è¯»å–
        input_file = sys.argv[1]
        mode = sys.argv[2] if len(sys.argv) > 2 else "base"
        
        with open(input_file, 'r') as f:
            text = f.read()
        
        result = compress_memory(text, mode)
        print(json.dumps(result, ensure_ascii=False, indent=2))
    else:
        # è¿è¡Œæ¼”ç¤º
        demo()
